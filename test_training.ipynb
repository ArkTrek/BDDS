{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: keras in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (2.13.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ar646\\desktop\\projects\\bdd\\pluto\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy tensorflow matplotlib keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Path to your datasets (adjust as needed)\n",
    "data_dir = 'dataset'  # Ensure it contains subfolders for each class (e.g., 'Brain Tumor', 'Alzheimers', etc.)\n",
    "\n",
    "# Image size and batch settings\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 5  # Reduced epochs for quicker training\n",
    "\n",
    "# Create ImageDataGenerator instances for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 20% validation split\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Use 'training' subset\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Use 'validation' subset\n",
    ")\n",
    "\n",
    "# Get the number of classes (diseases)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Define multiple CNN models (Ensemble)\n",
    "def build_model_1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def build_model_2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def build_model_3():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Compile the models\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create three models for the ensemble\n",
    "model_1 = build_model_1()\n",
    "model_2 = build_model_2()\n",
    "model_3 = build_model_3()\n",
    "\n",
    "compile_model(model_1)\n",
    "compile_model(model_2)\n",
    "compile_model(model_3)\n",
    "\n",
    "# Callbacks for early stopping and checkpointing\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train all models individually\n",
    "history_1 = model_1.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples / batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples / batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples / batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples / batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "history_3 = model_3.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples / batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples / batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Combine the predictions of all models\n",
    "def ensemble_predictions(models, test_generator):\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        preds = model.predict(test_generator, steps=test_generator.samples // batch_size)\n",
    "        predictions.append(preds)\n",
    "    \n",
    "    # Average the predictions\n",
    "    avg_predictions = np.mean(predictions, axis=0)\n",
    "    return avg_predictions\n",
    "\n",
    "# Ensemble of the three models\n",
    "models = [model_1, model_2, model_3]\n",
    "ensemble_preds = ensemble_predictions(models, validation_generator)\n",
    "\n",
    "# Save final ensemble model\n",
    "for i, model in enumerate(models):\n",
    "    model.save(f'ensemble_model_{i+1}.h5')\n",
    "\n",
    "# Plot training and validation accuracy and loss for model_1 (repeat for other models if needed)\n",
    "acc = history_1.history['accuracy']\n",
    "val_acc = history_1.history['val_accuracy']\n",
    "loss = history_1.history['loss']\n",
    "val_loss = history_1.history['val_loss']\n",
    "epochs_range = range(len(acc))  # Adjust based on actual epochs run\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy - Model 1')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss - Model 1')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 6\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to training and validation datasets\n",
    "train_dir = 'dataset/training'\n",
    "val_dir = 'dataset/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54320 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the training and validation datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',  # One-hot encoded labels\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18022 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',  # One-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation (simple CNN)\n",
    "model = models.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(224, 224, 3)),  # Normalize images\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')  # 6 classes\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1698/1698 [==============================] - 2455s 1s/step - loss: 0.1082 - accuracy: 0.9700 - val_loss: 0.0611 - val_accuracy: 0.9827\n",
      "Epoch 2/5\n",
      "1698/1698 [==============================] - 2528s 1s/step - loss: 0.0404 - accuracy: 0.9886 - val_loss: 0.1218 - val_accuracy: 0.9720\n",
      "Epoch 3/5\n",
      "1698/1698 [==============================] - 2456s 1s/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.0564 - val_accuracy: 0.9855\n",
      "Epoch 4/5\n",
      "1698/1698 [==============================] - 2387s 1s/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 0.0736 - val_accuracy: 0.9814\n",
      "Epoch 5/5\n",
      "1698/1698 [==============================] - 2390s 1s/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0615 - val_accuracy: 0.9857\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ar646\\Desktop\\Projects\\BDD\\pluto\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('bdc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - 141s 249ms/step - loss: 0.0615 - accuracy: 0.9857\n",
      "Validation Accuracy: 98.57%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "val_loss, val_acc = model.evaluate(validation_dataset)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pluto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
